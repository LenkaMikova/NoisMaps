---
title: "DP_hluk_04 - model GB"
format: html
editor: visual
jupyter: python3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require(gbm)) install.packages("gbm")
if (!require(caret)) install.packages("caret")
if (!require(ggplot2)) install.packages("ggplot2")

library(gbm)
library(caret)
library(ggplot2)
library(data.table)
```

# Gradient Boosting Model

## Načtení dat

```{r data-loading, include=FALSE}
setwd("E:/Skola/+M-PVZP/+DP/model/DP_hluk")
input_dir <- "F:/Skola/+M-PVZP/+DP/model/DP_hluk"
dtaM <- fread("dta_noOut.csv")

selected_variables <- c("L8_NDVI_Max", "S2_ISA", "VIIRS","LDEN")
#dtaM <- dtaM[, !removed_variables, with = FALSE]
dtaM <- dtaM[, ..selected_variables]
dtaM[, LDEN := as.factor(LDEN)]
head(dtaM)

```

## Rozdělení dat

```{r}
set.seed(123)
n <- nrow(dtaM)
train_index <- sample(1:n, 0.7 * n)  # 70% training data
remaining_index <- setdiff(1:n, train_index)
valid_index <- sample(remaining_index, 0.5 * length(remaining_index))  # 15% validation data
test_index <- setdiff(remaining_index, valid_index)  # 15% test data

train_data <- dtaM[train_index]
valid_data <- dtaM[valid_index]
test_data <- dtaM[test_index]
```

## Optimalizace hyperparametrů Gradient Boosting

```{r gbm-hyperparameter-tuning}

control <- trainControl(method = "cv", number = 5)

# Grid hledani hyperparametru
tune_grid <- expand.grid(
  n.trees = c(100, 200, 500, 1000, 2000, 5000),
  interaction.depth = c(1, 3, 5, 7),
  shrinkage = c(0.01, 0.05, 0.1),
  n.minobsinnode = c(10, 20, 30)
)
```

```{r}
# trenovani GB dle vytuneni
set.seed(123)
gbm_tuned <- train(
  LDEN ~ ., 
  data = train_data, 
  method = "gbm",
  trControl = control,
  tuneGrid = tune_grid,
  verbose = FALSE
)

# Best model - tuning
print(gbm_tuned$bestTune)
```

## Trénink modelu Gradient Boosting s optimalizovanými parametry

```{r gbm-model-training}
# trenovani - optimalni parametry
set.seed(123)
gbm_model <- gbm(
  formula = LDEN ~ .,
  data = train_data,
  distribution = "gaussian",
  n.trees = gbm_tuned$bestTune$n.trees,
  interaction.depth = gbm_tuned$bestTune$interaction.depth,
  shrinkage = gbm_tuned$bestTune$shrinkage,
  n.minobsinnode = gbm_tuned$bestTune$n.minobsinnode,
  verbose = FALSE
)
```

### Důležitost proměnných

```{r}
library(ggplot2)

# Získání důležitosti proměnných
importance_df <- summary(gbm_model)

# Přejmenování sloupců pro lepší přehlednost
colnames(importance_df) <- c("Variable", "Importance")

# Vykreslení grafu

custom_colors <- c("#bcbd22","#17becf", "#2ca02c", "#d62728", "#9467bd","#ff7f0e")

ggplot(importance_df, aes(x = reorder(Variable, Importance), y = Importance, fill = Variable)) +
  geom_col(show.legend = FALSE) +
  geom_text(aes(label = round(Importance, 1)),  # Přidání hodnot
            hjust = 1, size = 5) +  
  coord_flip() +  
  scale_fill_manual(values = custom_colors) +
  theme_minimal() +
  labs(title = "Relativní důležitost pro metodu Gradient Boosting",
       x = "Proměnná", y = "Relativní vliv (%)") +
  theme(axis.text = element_text(size = 12), 
        axis.title = element_text(size = 14),
        plot.title = element_text(size = 16, face = "bold", hjust = 0.5))

```

## Trénink modelu na upravených parametrech

```{r gbm-model-training}
# trenovani - upravené parametry
set.seed(123)
gbm_model <- gbm(
  formula = LDEN ~ .,
  data = train_data,
  distribution = "gaussian",
  n.trees = 1000,
  interaction.depth = 5,
  shrinkage = 0.05,
  n.minobsinnode = 50,
  verbose = FALSE
)
```

# Vyhodnocení modelu

```{r}
test_predicted <- predict(gbm_model_updated, test_data, n.trees = gbm_tuned$bestTune$n.trees)
test_actual <- as.numeric(test_data$LDEN)

train_predicted <- predict(gbm_model_updated, train_data, n.trees = gbm_tuned$bestTune$n.trees)
train_actual <- as.numeric(train_data$LDEN)

valid_predicted <- predict(gbm_model_updated, valid_data, n.trees = gbm_tuned$bestTune$n.trees)
valid_actual <- as.numeric(valid_data$LDEN)


test_predicted <- as.numeric(test_predicted)
train_predicted <- as.numeric(train_predicted)
valid_predicted <- as.numeric(valid_predicted)


train_rmse <- sqrt(mean((train_predicted - train_actual)^2))
train_mae <- mean(abs(train_predicted - train_actual))
train_rsq <- cor(train_predicted, train_actual)^2

cat("RMSE na trénovacích datech:", train_rmse, "\n")
cat("MAE na trénovacích datech:", train_mae, "\n")
cat("R-squared na trénovacích datech:", train_rsq, "\n\n")

test_rmse <- sqrt(mean((test_predicted - test_actual)^2))
test_mae <- mean(abs(test_predicted - test_actual))
test_rsq <- cor(test_predicted, test_actual)^2

cat("RMSE na testovacích datech:", test_rmse, "\n")
cat("MAE na testovacích datech:", test_mae, "\n")
cat("R-squared na testovacích datech:", test_rsq, "\n\n")

valid_rmse <- sqrt(mean((valid_predicted - valid_actual)^2))
valid_mae <- mean(abs(valid_predicted - valid_actual))
valid_rsq <- cor(valid_predicted, valid_actual)^2

cat("RMSE na validačních datech:", valid_rmse, "\n")
cat("MAE na validačních datech:", valid_mae, "\n")
cat("R-squared na validačních datech:", valid_rsq, "\n")

```

