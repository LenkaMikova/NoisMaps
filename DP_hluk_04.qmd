---
title: "DP_hluk_04 - model GB"
format: html
editor: visual
jupyter: python3
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
if (!require(gbm)) install.packages("gbm")
if (!require(caret)) install.packages("caret")
if (!require(ggplot2)) install.packages("ggplot2")

library(gbm)
library(caret)
library(ggplot2)
```

# Gradient Boosting Model

## Načtení dat

```{r data-loading, include=FALSE}

setwd("F:/Skola/+M-PVZP/+DP/model/DP_hluk")
input_dir <- "F:/Skola/+M-PVZP/+DP/model/DP_hluk"
dtaM <- fread("dta.csv")  


dtaM <- dtaM[, !c("ID", "noiseLevel", "sourceLDEN"), with = FALSE]

```

## Rozdělení dat

```{r}
set.seed(123)
n <- nrow(dtaM)
train_index <- sample(1:n, 0.7 * n)  # 70% training data
remaining_index <- setdiff(1:n, train_index)
valid_index <- sample(remaining_index, 0.5 * length(remaining_index))  # 15% validation data
test_index <- setdiff(remaining_index, valid_index)  # 15% test data

train_data <- dtaM[train_index]
valid_data <- dtaM[valid_index]
test_data <- dtaM[test_index]
```

## Optimalizace hyperparametrů Gradient Boosting

```{r gbm-hyperparameter-tuning}

control <- trainControl(method = "cv", number = 5)

# Grid hledani hyperparametru
tune_grid <- expand.grid(
  n.trees = c(100, 200, 500, 1000, 2000),
  interaction.depth = c(1, 3, 5, 7),
  shrinkage = c(0.01, 0.1),
  n.minobsinnode = c(10, 20)
)
```

```{r}
# trenovani GB dle vytuneni
set.seed(123)
gbm_tuned <- train(
  LDEN ~ ., 
  data = train_data, 
  method = "gbm",
  trControl = control,
  tuneGrid = tune_grid,
  verbose = FALSE
)

# Best model - tuning
print(gbm_tuned$bestTune)
```

## Trénink modelu Gradient Boosting s optimalizovanými parametry

```{r gbm-model-training}
# trenovani - optimalni parametry
set.seed(123)
gbm_model <- gbm(
  formula = LDEN ~ .,
  data = train_data,
  distribution = "gaussian",
  n.trees = 1000,
  interaction.depth = 9,
  shrinkage = gbm_tuned$bestTune$shrinkage,
  n.minobsinnode = 10,
  verbose = FALSE
)

summary(gbm_model)
```

```{r}
# Vyhodnoceni puvidniho modelu na testovacich datech
test_predicted <- predict(gbm_model, test_data, n.trees = gbm_tuned$bestTune$n.trees)
rmse <- sqrt(mean((test_predicted - test_data$LDEN)^2))
mae <- mean(abs(test_predicted - test_data$LDEN))
rsq <- cor(test_predicted, test_data$LDEN)^2

cat("Původní model:\n")
cat("RMSE na testovacích datech:", rmse, "\n")
cat("MAE na testovacích datech:", mae, "\n")
cat("R-squared na testovacích datech:", rsq, "\n")
```

```{r}
variable_importance <- summary(gbm_model, n.trees = gbm_tuned$bestTune$n.trees, plotit = FALSE)
variable_importance_df <- data.frame(
  Variable = rownames(variable_importance),
  RelativeInfluence = variable_importance[, "rel.inf"]
)

ggplot(variable_importance_df, aes(x = reorder(Variable, RelativeInfluence), y = RelativeInfluence)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  coord_flip() +
  labs(
    title = "Feature Importance - Gradient Boosting Model",
    x = "Variables",
    y = "Relativ influence"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Filtrace dat podle Relative influence

```{r}
filtered_data <- dtaM[, !c("VIIRS_log", "CO_log", "CH4_log", "HCHO_log", "NO2_log", "L8_NDVI_Median", "L8_ISA", "L8_UI", "S2_MNDWI", "L8_NDBI"), with = FALSE]

set.seed(123)
n <- nrow(filtered_data)
train_index <- sample(1:n, 0.7 * n)
remaining_index <- setdiff(1:n, train_index)
valid_index <- sample(remaining_index, 0.5 * length(remaining_index))
test_index <- setdiff(remaining_index, valid_index)

train_data <- filtered_data[train_index]
valid_data <- filtered_data[valid_index]
test_data <- filtered_data[test_index]
```

```{r}
# Trénink modelu Gradient Boosting s aktualizovanými proměnnými
set.seed(123)
gbm_model_updated <- gbm(
  formula = LDEN ~ .,
  data = train_data,
  distribution = "gaussian",
  n.trees = 200,
  interaction.depth = gbm_tuned$bestTune$interaction.depth,
  shrinkage = gbm_tuned$bestTune$shrinkage,
  n.minobsinnode = gbm_tuned$bestTune$n.minobsinnode,
  verbose = FALSE
)

# Vyhodnocení nového modelu na testovacích datech
test_predicted <- predict(gbm_model_updated, test_data, n.trees = gbm_tuned$bestTune$n.trees)
rmse <- sqrt(mean((test_predicted - test_data$LDEN)^2))
mae <- mean(abs(test_predicted - test_data$LDEN))
rsq <- cor(test_predicted, test_data$LDEN)^2

cat("Aktualizovaný model:\n")
cat("RMSE na testovacích datech:", rmse, "\n")
cat("MAE na testovacích datech:", mae, "\n")
cat("R-squared na testovacích datech:", rsq, "\n")
```
